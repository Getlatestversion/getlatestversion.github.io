{"version":"https://jsonfeed.org/version/1","title":"Home on GetLatestVersion – Europe","description":"Recent content in Home on GetLatestVersion – Europe","home_page_url":"http://www.getlatestversion.eu/","feed_url":"http://www.getlatestversion.eu/index.json","items":[{"title":"Migrating work items from Jira to Azure DevOps","date_published":"2020-08-18T17:30:00+02:00","date_modified":"2020-08-18T17:30:00+02:00","id":"http://www.getlatestversion.eu/2020/08/migrating-work-items-from-jira-to-azure-devops/","url":"http://www.getlatestversion.eu/2020/08/migrating-work-items-from-jira-to-azure-devops/","author":{"name":"Alessandro Alpi"},"content_html":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cp\u003eMigrations are hard tasks to deal with. Not just for IT. Working with the culture of many companies, I\u0026rsquo;ve got confirmation that the tool should be considered at the end of the migration process. After setting up the ceremonies and switching the methodologies from legacy to lean/iterative, it comes finally to choose from the available tools (\u003cem\u003eenterprise awareness\u003c/em\u003e) and including new ones. The goal is to get all the stuff which fits the real scenario.\u003c/p\u003e\n\u003cp\u003eThis post is a quick step by step guide to migrate work items from \u003ca href=\"https://www.atlassian.com/software/jira\"\u003eJira cloud\u003c/a\u003e to \u003ca href=\"https://azure.microsoft.com/it-it/services/devops/\"\u003eAzure DevOps Services\u003c/a\u003e. I\u0026rsquo;m going to describe the last step of one of my customers\u0026rsquo; migration.\u003c/p\u003e\n\u003ch2 id=\"table-of-content\"\u003eTable of content\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#Getting-started\"\u003eGetting started\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#The-software-selection\"\u003eThe software selection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#Executing-the-tool\"\u003eExecuting the tool\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#How-to-export-Jira-issues\"\u003eHow to export Jira issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#How-to-import-to-Azure-DevOps\"\u003eHow to import to Azure DevOps\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#Conclusions\"\u003eConclusions\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"getting-started\"\u003eGetting started\u003c/h2\u003e\n\u003cp\u003eBefore going in-depth with technical details, I would like to share some tips. As we have already said, the migrations are complex tasks. Mandatory requirements should be a strong knowledge in terms of business and team management, enterprise awareness and years of experience on different real scenarios.\u003c/p\u003e\n\u003cp\u003eWe must avoid any decision if our ideas and targets are not clear. Another important requirement is to understand in depth the workflows you will work on, both the legacy one and the new one you\u0026rsquo;re figuring out. Some of the question we should ask ourselves are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDo we require these steps? And what about these work items?\u003c/li\u003e\n\u003cli\u003eIs this state workflow good for us? Should we change it? How?\u003c/li\u003e\n\u003cli\u003eDo we require to preserve relationships and items\u0026rsquo; history?\u003c/li\u003e\n\u003cli\u003eCan we keep something which is working very well now? If so, what tools we\u0026rsquo;re thinking about?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"the-software-selection\"\u003eThe software selection\u003c/h2\u003e\n\u003cp\u003eThe software selection has ended up on a tool made by \u003ca href=\"https://solidify.se/\"\u003eSolidify\u003c/a\u003e (Thanks to the experienced members of our \u003ca href=\"https://www.getlatestversion.eu/\"\u003egetlatestversion.eu\u003c/a\u003e community). Anyways, you can find more of them. For example:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://ilclubdellesei.blog/2018/05/21/import-from-jira-to-vsts-in-5-steps/\"\u003eTFS4JIRA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.codewrecks.com/blog/index.php/2019/01/19/import-work-item-from-external-system-to-azure-devops/\"\u003eImporting work items to Azure DevOps by Gian Maria Ricci\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ilclubdellesei.blog/2018/05/21/import-from-jira-to-vsts-in-5-steps/\"\u003eJiraToVsts \u003c/a\u003e (via \u003ca href=\"https://www.getlatestversion.eu/it/authors/phenix/\"\u003eMichele Ferracin\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen exporting from Jira, the CLI implemented by \u003ca href=\"https://solidify.se/\"\u003eSolidify\u003c/a\u003e connects to the Jira server (cloud by default and on-premises when configured), executes a \u003ca href=\"https://www.atlassian.com/software/jira/guides/expand-jira/jql\"\u003eJQL\u003c/a\u003e query for extracting the Jira so-called \u0026ldquo;Issues\u0026rdquo;, evaluates and applies the mapping between users, work items, relationships and states, and exports a JSON file for each item.\u003c/p\u003e\n\u003cp\u003eWhen importing to Azure DevOps, the CLI imports the output JSON files using the same mapping configured into the configuration file in the exporting phase.\u003c/p\u003e\n\u003cp\u003eWhy this tool? Because it has a couple of simple command lines and it consumes a JSON configuration which is clear. Additionally, it has many default behaviours, like the built-in configuration for \u003cem\u003eScrum\u003c/em\u003e, \u003cem\u003eagile\u003c/em\u003e and \u003cem\u003ebasic\u003c/em\u003e process templates, which allows us to forget about the complexity of both the source and target software.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"#Intro\"\u003eBack to top\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"executing-the-tool\"\u003eExecuting the tool\u003c/h2\u003e\n\u003cp\u003eThe scenario (Jira) has been configured with many states, sometimes with overlapping meaning (due to the legacy setup and different team\u0026rsquo;s approach) and with custom workflows/links. On the other hand, Azure DevOps side, I\u0026rsquo;ve created a customized Scrum template, with just two new work item types, which should support some of the customized source behaviours, and a couple of new states. So the tool has been configured as depicted in the following JSON (just a subset of maps):\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"./01-config.png\" alt=\"config\"\u003e\u003c/p\u003e\n\u003cp\u003eJust that. Notice that we can configure project names, the JQL query for gathering issues, working folder names and the file for the user mappings.\u003c/p\u003e\n\u003cp\u003eFirst, download \u003ca href=\"https://github.com/solidify/jira-azuredevops-migrator/releases\"\u003ethe latest release of the CLI from GitHub\u003c/a\u003e. Then follow these steps-\u003c/p\u003e\n\u003ch3 id=\"how-to-export-jira-issues\"\u003eHow to export Jira issues\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ecreate a folder called C:/Temp/JiraExport (you can configure this editing the JSON config file)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ecreate a file called \u0026ldquo;users.txt\u0026rdquo; within that folder and put into it a list of \u003ccode\u003ejirauser@domain.ext=AzDOs@domain.ext\u003c/code\u003e records\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eplease note that the Jira user can be represented without the domain, depending on its configuration\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ecopy the JSON configuration file (based on the template we\u0026rsquo;re going to apply when importing) into the JiraExport folder\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emodify the file in the maps section: link-map, type-map, field-map, and so on.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eget the credentials (as admin) and the Jira server URL\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003emake your command line, which should look like the following:\n\u003ccode\u003ejira-export -u username@domain.ext -p userPwd --url https://jiraurl.ext --config config-scrum.json --force\u003c/code\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003erun the command and look for the JSON files into the JiraExport folder\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elook for any warning/error like the following and correct them (this will help you to import without any breaking change)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"./02-errors.png\" alt=\"errors\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003ca href=\"#Intro\"\u003eBack to top\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"how-to-import-to-azure-devops\"\u003eHow to import to Azure DevOps\u003c/h3\u003e\n\u003cp\u003eIt\u0026rsquo;s time to execute the second command line, \u003cstrong\u003ewi-import\u003c/strong\u003e. As we can see, we have to get a personal access token (PAT) from Azure DevOps, as described \u003ca href=\"https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops\u0026amp;tabs=preview-page\"\u003ein the documentation\u003c/a\u003e, with the full access.\u003c/p\u003e\n\u003cp\u003eComing back to the configuration, we should pay attention to \u003ccode\u003ebase-area-path\u003c/code\u003e and \u003ccode\u003ebase-iteration-path\u003c/code\u003e. With these, we can choose the target of our migration, in terms of area and iteration. This means that we can manage our items after the import has been completed. With a query, for example, we can remove everything and start over with the migration. Cool. The command should like the following:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewi-import --token PAT --url https://dev.azure.com/org --config config-scrum.json --force\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"./03-import.png\" alt=\"import\"\u003e\u003c/p\u003e\n\u003cp\u003eAfter ten minutes we\u0026rsquo;ve got new areas and iterations:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"./04-iterations.png\" alt=\"iterations\"\u003e  \u003cimg src=\"./05-areas.png\" alt=\"areas\"\u003e\u003c/p\u003e\n\u003cp\u003eThe Azure DevOps hierarchy of items (except for the Features, which I\u0026rsquo;ve not mapped) has been preserved and also the history of any item:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"./06-history.png\" alt=\"history\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"#Intro\"\u003eBack to top\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003c/h2\u003e\n\u003cp\u003eIn a couple of days, we\u0026rsquo;ve migrated everything related to work items from Jira to Azure DevOps. Most of the time should be invested in configuring the JSON mappings and, for sure, to check for the errors caught during exporting items. Finally, after importing into AzDOs, you can start over and over, removing all the items under the pre-configured area/iteration, until everything looks good.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"#Intro\"\u003eBack to top\u003c/a\u003e\u003c/p\u003e\n"},{"title":"Git Cherry-Pick for a strategic harvest","date_published":"2020-07-13T03:00:00+02:00","date_modified":"2020-07-13T03:00:00+02:00","id":"http://www.getlatestversion.eu/2020/07/git-cherry-pick-for-a-strategic-harvest/","url":"http://www.getlatestversion.eu/2020/07/git-cherry-pick-for-a-strategic-harvest/","author":{"name":"Bartolomeo Lombardi"},"content_html":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIT companies which develop and sell software product are always focused on delivering new features to propose new versions of them to the final client, while still considering the maintenance of the previous release.\nGenerally, we are talking about projects of millions of lines of code that requires multiple developing teams located around the world with strong coordination and collaboration among them, in which it is necessary to handle multiple versions of the same product with a significant number of release branches. Fixing a bug on multiple branches is a complex task because the developer needs to backport the same fix in the various release branches possible with Git and it is called \u0026ldquo;cherry-picking\u0026rdquo;.\u003c/p\u003e\n\u003ch1 id=\"git-cherry-pick\"\u003eGit cherry-pick\u003c/h1\u003e\n\u003cp\u003eOne of the most powerful Git commands is Cherry-pick. It takes one or more commits as input parameters and shifts them to a different branch, by creating a new commit in the process.\u003c/p\u003e\n\u003cp\u003eCherry-pick is commonly used in many Git workflows such as the Azure DevOps team’s, described in the following \u003ca href=\"https://devblogs.microsoft.com/devops/improving-azure-devops-cherry-picking/\"\u003earticle\u003c/a\u003e, see the image reported below for a visual representation of the workflow.\n\u003cimg src=\"cherry-pick-workflow.jpg\" alt=\"Cherry-Pick: way of working\"\u003e\u003c/p\u003e\n\u003cp\u003eEvery time a developer works with many version of the same product it is essential to ensure all the reported bugs have been fixed in as many version as possible. Cherry-picking happens on the main branch to avoid deploying a new release with the same bug.\u003c/p\u003e\n\u003ch2 id=\"azure-devops-repos\"\u003eAzure DevOps Repos\u003c/h2\u003e\n\u003cp\u003eAzure DevOps provides cherry-picking of a completed Pull Request (PR) or of a single commit by clicking a dedicated button. The process will create a new PR with the same fix.\n\u003cimg src=\"azdo-cp.jpg\" alt=\"Cherry-Pick Azure DevOps\"\u003e\u003c/p\u003e\n\u003cp\u003eMoreover, a \u003ca href=\"https://github.com/microsoft/azure-repos-pr-multi-cherry-pick\"\u003ePR Multi-Cherry-Pick\u003c/a\u003e is possible by means of an open source extension available on Azure DevOps Marketplace.\u003c/p\u003e\n\u003cp\u003eIf Azure DevOps displays a warning about the cherry-picking not being performed automatically (see image below) this is related to conflicts generated during the merge, therefore it has to be performed locally.\n\u003cimg src=\"azdo-cp-error.jpg\" alt=\"Azure DevOps conflict errors\"\u003e\u003c/p\u003e\n\u003cp\u003eMany development environments integrated with Git can perform this local operation by graphic user interface. Best candidates are Visual Studio or VS Code.\u003c/p\u003e\n\u003ch1 id=\"git-cherry-pick---continue\"\u003eGit cherry-pick \u0026ndash;continue\u003c/h1\u003e\n\u003cp\u003eA few steps are needed to execute the following command \u003ca href=\"https://git-scm.com/docs/git-cherry-pick\"\u003egit cherry-pick\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe first step is noting of the hash commit value to cherry-pick. If within a PR, the list of commits is available in the \u003cstrong\u003eCommits\u003c/strong\u003e tab in Azure Repos:\n\u003cimg src=\"azdo-commits-tab.jpg\" alt=\"Commit table on Azure DevOps\"\u003e\u003c/p\u003e\n\u003cp\u003eOnce you are on the branch (\u003ccode\u003egit checkout \u0026lt;branch-name\u0026gt;\u003c/code\u003e) that you want to commit, the following command must be executed \u003ccode\u003egit cherry-pick \u0026lt;commit\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eKnowing that the cherry-pick command shown in the previous example can generate another conflict, once the code is merged manually you need to run the \u003ccode\u003egit cherry-pick --continue\u003c/code\u003e to proceed. If you want to abort the process simply run git \u003ccode\u003echerry-pick --abort\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eAll you need to do now is to perform \u003ccode\u003egit push\u003c/code\u003e to align the remote.\u003c/p\u003e\n"},{"title":"Flaky builds","date_published":"2020-06-07T20:00:00+01:00","date_modified":"2020-06-07T20:00:00+01:00","id":"http://www.getlatestversion.eu/2020/06/flaky-builds/","url":"http://www.getlatestversion.eu/2020/06/flaky-builds/","author":{"name":"Giulio Vian"},"content_html":"\u003cp\u003eThe topic is huge and I do not have the room to go through all the details in one post, so I stick to a cursory view. I will sprinkle references to additional material so you can deep dive later.\u003c/p\u003e\n\u003ch2 id=\"what-is-a-flaky-build\"\u003eWhat is a \u0026lsquo;flaky\u0026rsquo; build?\u003c/h2\u003e\n\u003cp\u003eA \u0026lsquo;flaky\u0026rsquo; build is a build whose outcome is, in some ways, unpredictable. This is generally bad because you expect your CI to be algorithmic, deterministic, with no randomness. The worse consequence of an unpredictable build lies in the future: that day when you run the same build, maybe in the hurry of delivering a patch, and it fails unexpectedly. Some may think that is is just another piece of evidence for Murphy’s Law\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e, which applies to all time and space.\nThe unpredictability may be subtle; for example, the build always succeeds but its results are never quite the same.\nIn the following, I will review the most common flakiness scenarios.\u003c/p\u003e\n\u003ch2 id=\"same-source-different-binaries\"\u003eSame source, different binaries\u003c/h2\u003e\n\u003cp\u003eHave you tried comparing binaries built on two different machines? More often than not, they will be different! Even if you use the exact same source code version. Worse, even on the same machine, rebuilding the same code at a later time will produce different binaries.\u003c/p\u003e\n\u003cp\u003eMy first example is a .NET 4.x assembly: the next picture shows the binary difference between files built from the same sources a few minutes apart.\n\u003cimg src=\"dotnet4.8-hexdiff.png\" alt=\"Binary diff of Exes\"\u003e\nTraditionally Microsoft tools embedded some kind of build timestamp in binaries for a number of reason, especially to help Windows\u0026rsquo; Loader\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003eI obtained a similar result with Maven building a JAR package, I used Beyond Compare to compare more easily.\n\u003cimg src=\"mvn-diff1.png\" alt=\"JAR content difference\"\u003e\nThe difference is in the \u003ccode\u003epom.properties\u003c/code\u003e manifest, which contains a time-stamp marking when the package was built.\n\u003cimg src=\"mvn-diff2.png\" alt=\"Maven manifest difference\"\u003e\u003c/p\u003e\n\u003cp\u003eThere are ways to fix these behaviors and join the camp of repeatable builds, like myself.\u003c/p\u003e\n\u003ch3 id=\"why-should-i-care\"\u003eWhy should I care?\u003c/h3\u003e\n\u003cp\u003eThe ability to compare binaries helps or is even required in many circumstances:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etroubleshooting, you can quickly compare a binary file generated on your machine with another from unknown source;\u003c/li\u003e\n\u003cli\u003edeployment, you can skip copying/deploying binary identical files;\u003c/li\u003e\n\u003cli\u003epatching, generating binary patches is easier;\u003c/li\u003e\n\u003cli\u003eauditing, you can demonstrate the version of code that is running in production matches source code;\u003c/li\u003e\n\u003cli\u003esecurity, the binary hasn\u0026rsquo;t been tampered by an attacker.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHope this convince you that these goals are worth your time and effort. Auditing and security are becoming of greater importance these days.\u003c/p\u003e\n\u003ch3 id=\"reproducible-builds\"\u003eReproducible builds\u003c/h3\u003e\n\u003cp\u003eLet\u0026rsquo;s state a clear goal, we want reproducible builds that generate identical \u003cem\u003emain\u003c/em\u003e artifacts when using the same version of source code.\nWhat do I mean with \u003cem\u003emain\u003c/em\u003e artifacts? That we allow for ancillary artifacts to change at every run; a trivial example is a build log or release note file. We forbid differences in executable binaries, data or configuration files, scripts and tools.\nWith this definition, a release note file displaying a build id or timestamp is fine.\u003c/p\u003e\n\u003cp\u003eTo achieve this goal, you have to look at the tools\u0026rsquo; manuals. I will detail a few common scenarios.\nIn addition to the following suggestions, you have to consider a proper archival and versioning of the toolchain in use to build the software. A newer version of compiler, SDK, build may produce different results.\u003c/p\u003e\n\u003ch3 id=\"net-reproducible-builds\"\u003e.NET Reproducible builds\u003c/h3\u003e\n\u003cp\u003eThe Roslyn C# compiler offers the \u003ca href=\"https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-options/deterministic-compiler-option\"\u003e\u003ccode\u003e-deterministic\u003c/code\u003e\u003c/a\u003e flag a few years now, that is, from Visual Studio 2015. You turn on the option setting the \u003ccode\u003eDeterministic\u003c/code\u003e MSBuild property to \u003ccode\u003etrue\u003c/code\u003e in the project file.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-xml\" data-lang=\"xml\"\u003e  \u003cspan style=\"color:#f92672\"\u003e\u0026lt;PropertyGroup\u0026gt;\u003c/span\u003e\n    \u003cspan style=\"color:#f92672\"\u003e\u0026lt;Deterministic\u0026gt;\u003c/span\u003etrue\u003cspan style=\"color:#f92672\"\u003e\u0026lt;/Deterministic\u0026gt;\u003c/span\u003e\n    \u003cspan style=\"color:#f92672\"\u003e\u0026lt;PathMap\u0026gt;\u003c/span\u003e$(MSBuildThisFileDirectory)=\\src\u003cspan style=\"color:#f92672\"\u003e\u0026lt;/PathMap\u0026gt;\u003c/span\u003e\n  \u003cspan style=\"color:#f92672\"\u003e\u0026lt;/PropertyGroup\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBy the way, you do not need to rush editing you project files to set these properties. You can add a \u003ccode\u003eDirectory.Build.props\u003c/code\u003e file\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e at the root of your project and the setting will be applied to all projects under the same directory.\nI have a good news: .NET Core SDK projects use the \u003ccode\u003edeterministic\u003c/code\u003e flag by default. The bad news is that it is not enough in some cases, but keep on reading.\u003c/p\u003e\n\u003cp\u003eIn the above example, you have surely noted another property, \u003ccode\u003ePathMap\u003c/code\u003e, which matches the \u003ca href=\"https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-options/pathmap-compiler-option\"\u003e\u003ccode\u003e-pathmap\u003c/code\u003e\u003c/a\u003e compiler option. This option alters the paths embedded in executables and PDBs\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e and is especially useful when building on a server. Typically each agent on the server has a different base directory, and the generated files embed the agent specific path. With \u003ccode\u003ePathMap\u003c/code\u003e you define a conventional directory (\u003ccode\u003e\\src\u003c/code\u003e in the example) independent from the effective directory used for the build.\nA useful resource is Jared Parsons\u0026rsquo; post \u003ca href=\"https://blog.paranoidcoding.com/2016/04/05/deterministic-builds-in-roslyn.html\"\u003e\u003cem\u003eDeterministic builds in Roslyn\u003c/em\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"maven-java-reproducible-builds\"\u003eMaven (Java) Reproducible builds\u003c/h3\u003e\n\u003cp\u003eIt is very easy to replace the timestamp in \u003ccode\u003epom.properties\u003c/code\u003e, just add a \u003ccode\u003eproject.build.outputTimestamp\u003c/code\u003e property\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-xml\" data-lang=\"xml\"\u003e  \u003cspan style=\"color:#f92672\"\u003e\u0026lt;properties\u0026gt;\u003c/span\u003e\n    \u003cspan style=\"color:#f92672\"\u003e\u0026lt;project.build.outputTimestamp\u0026gt;\u003c/span\u003e2020-06-06T22:12:34Z\u003cspan style=\"color:#f92672\"\u003e\u0026lt;/project.build.outputTimestamp\u0026gt;\u003c/span\u003e\n  \u003cspan style=\"color:#f92672\"\u003e\u0026lt;/properties\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eto the \u003ccode\u003epom.xml\u003c/code\u003e file. This requires that you use a recent version (3.2 or later) of Maven plugins. You can find all the details in \u003ca href=\"https://maven.apache.org/guides/mini/guide-reproducible-builds.html\"\u003e\u003cem\u003eConfiguring for Reproducible Builds\u003c/em\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003epom.properties\u003c/code\u003e solves the simple issue but there are additional data, used during build, that can produce different outcomes. A more through approach use the \u003ca href=\"https://zlika.github.io/reproducible-build-maven-plugin/\"\u003eReproducible Build Maven Plugin\u003c/a\u003e which guarantees identical binaries given unchanged sources.\u003c/p\u003e\n\u003ch3 id=\"other-languages\"\u003eOther languages\u003c/h3\u003e\n\u003cp\u003eC/C++ developers can profitably study \u003ca href=\"https://blog.conan.io/2019/09/02/Deterministic-builds-with-C-C++.html\"\u003eAn introduction to deterministic builds with C/C++\u003c/a\u003e; this article explores the main issue on each major platform (Windows, Mac, and Linux).\nI recommend the \u003ca href=\"https://reproducible-builds.org/\"\u003ehttps://reproducible-builds.org/\u003c/a\u003e site for Linux and C/C++ information about Reproducible builds.\nC/C++ reproducible can be complex to implement, caring for lots of detail, so I do not even dare to start in a short article like this one.\u003c/p\u003e\n\u003cp\u003eGo language has its quirks too. You may want to avoid the C compiler and linker, using the \u003ccode\u003eCGO_ENABLED=0\u003c/code\u003e setting, or embrace complexity. The other main issue is path strings embedded  in binaries. The \u003ca href=\"https://golang.org/cmd/go/#hdr-Compile_packages_and_dependencies\"\u003e\u003ccode\u003e-trimpath\u003c/code\u003e\u003c/a\u003e flag, available with Go 1.13 and later, resolves using a conventional path (similar to C# \u003ccode\u003e-pathmap\u003c/code\u003e).\u003c/p\u003e\n\u003ch2 id=\"same-definition-different-set-of-files\"\u003eSame definition, different set of files\u003c/h2\u003e\n\u003cp\u003eDependencies are the next source of troubles for build predictability. I see this as a separate topic from reproducible builds because the focus is not the individual file you coded, but the general outcome and files outside your direct control.\u003c/p\u003e\n\u003cp\u003eThe issue caused by dependencies is simple to describe. Your project depends on, at least one, external file. The first time you build, you get a version of this external file, say v1.0. The next time you build, the version for the external file is different: it can be v1.0.1, v1.1, v2.0 or else.\u003c/p\u003e\n\u003cp\u003eWe can set apart four reasons for non-predictable outcomes when it comes to dependencies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLoose specification \u0026amp; newer packages versions available;\u003c/li\u003e\n\u003cli\u003eNewer versions available for indirect dependencies;\u003c/li\u003e\n\u003cli\u003eLoss of package source (direct or indirect);\u003c/li\u003e\n\u003cli\u003eChange in package manager and its algorithm.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"loose-dependencies-specifications\"\u003eLoose dependencies specifications\u003c/h3\u003e\n\u003cp\u003eEvery modern library manager permits to specify a strict or a loose rule for a dependent file. The strict rule states a unique version for the library package. A loose rule defines a range of acceptable versions.\nWhen the library author publishes a new version, what happens to your build depends on the rule. A strict rule will always retrieve the same version, a loose rule may force the package manager to download a different version. Let\u0026rsquo;s see a practical example.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"center\"\u003eDate\u003c/th\u003e\n\u003cth align=\"center\"\u003eDependency Rule\u003c/th\u003e\n\u003cth align=\"center\"\u003eAvailable versions\u003c/th\u003e\n\u003cth align=\"center\"\u003eVersion selected\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Jan\u003c/td\u003e\n\u003ctd align=\"center\"\u003e= 1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Jan\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u0026lt;= and \u0026lt;2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Feb\u003c/td\u003e\n\u003ctd align=\"center\"\u003e= 1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0, 1.1\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Feb\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u0026lt;= and \u0026lt;2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0, 1.1\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Mar\u003c/td\u003e\n\u003ctd align=\"center\"\u003e= 1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0, 1.1, 1.2, 2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Mar\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u0026lt;= and \u0026lt;2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0, 1.1, 1.2, 2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Apr\u003c/td\u003e\n\u003ctd align=\"center\"\u003e= 1.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.2, 2.0, 2.1\u003c/td\u003e\n\u003ctd align=\"center\"\u003eerror\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e1 Apr\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.0\u0026lt;= and \u0026lt;2.0\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.2, 2.0, 2.1\u003c/td\u003e\n\u003ctd align=\"center\"\u003e1.2\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eIn this example, after the author publishes a new minor version, the build (\u003cem\u003erectius\u003c/em\u003e the package manager) use the new minor version for the looser rule, while the strict rule stick to version 1.0.\nYou may have noticed the 7th line, the build using the strict rule fails because the required version of the package is no more available. This is not the scenario we will discuss in \u003ca href=\"#lost-source\"\u003e\u003cem\u003eLost source\u003c/em\u003e\u003c/a\u003e, but the solution is the same.\nNote that some package managers do not select the most recent version of a package (Maven is an example).\u003c/p\u003e\n\u003ch3 id=\"indirect-dependencies\"\u003eIndirect dependencies\u003c/h3\u003e\n\u003cp\u003eThe \u003ca href=\"#loose-dependencies-specifications\"\u003eabove\u003c/a\u003e scenario is very simple because it analyses a direct dependency, i.e. the code you are building directly depends on the specified library version.\nThis is rarely the case in practice: the libraries you use depends on other libraries and so on. On average a project has a couple of hundred dependencies, direct or indirect \u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003eWhile you can set very strict rules for your direct dependencies, you have no control on indirect dependencies. Only the library author can define the rules for the latter.\nLet\u0026rsquo;s see a simple example.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"diamond-dependency-graph.png\" alt=\"Diamond dependency graph\"\u003e\u003c/p\u003e\n\u003cp\u003eWe say that \u003cstrong\u003eLibrary C\u003c/strong\u003e is a transitive dependency for App.\n\u003cstrong\u003eLibrary A\u003c/strong\u003e requires at least version 2.0 of \u003cstrong\u003eLibrary C\u003c/strong\u003e while \u003cstrong\u003eLibrary C\u003c/strong\u003e requires a minimum 3.0 version. The package manager will pick version 3, which may have unexpected effects.\u003c/p\u003e\n\u003cp\u003eThere is a solution to this and the previous issue and is generally referred as \u003cem\u003elocking\u003c/em\u003e.\u003c/p\u003e\n\u003ch3 id=\"fixing-loose-specifications-and-indirect-dependencies\"\u003eFixing loose specifications and indirect dependencies\u003c/h3\u003e\n\u003cp\u003eThe most used library package managers offer a \u003cem\u003elocking\u003c/em\u003e mechanism: the tool evaluates the whole dependency graph, determining the set of version that satisfy all dependency rules, save the result in a  \u003cem\u003elock\u003c/em\u003e file, and use such result from now on without evaluating again. This mechanism is sometimes called \u003cem\u003epinning\u003c/em\u003e or \u003cem\u003efixing\u003c/em\u003e library versions, as you are taking a snapshot of dependency graph at a point in time.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNuGet\u003c/strong\u003e uses \u003ca href=\"https://github.com/NuGet/Home/wiki/Enable-repeatable-package-restore-using-lock-file\"\u003e\u003ccode\u003epackages.lock.json\u003c/code\u003e file\u003c/a\u003e to control locking. The presence of the file, even empty, triggers the mechanism. You can have this file at the project level (e.g. same directory as \u003ccode\u003e.csproj\u003c/code\u003e project file) or at the root of the Git repository, depending how you prefer managing dependencies.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMaven\u003c/strong\u003e requires that you use the \u003ca href=\"http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Dependency_Management\"\u003e\u003ccode\u003e\u0026lt;dependencyManagement\u0026gt;\u003c/code\u003e stanza\u003c/a\u003e to define the versions for direct and indirect dependencies. This mechanism is not 100% robust, so the community has devise some plugins to help manage the list and detect violations like \u003ca href=\"https://github.com/vandmo/dependency-lock-maven-plugin\"\u003edependency-lock-maven-plugin\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGradle\u003c/strong\u003e offers a very sophisticated mechanism based on a set of \u003ca href=\"https://docs.gradle.org/current/userguide/dependency_locking.html\"\u003elock files\u003c/a\u003e. It is an opt-in mechanism that requires modification to the \u003ccode\u003ebuild.gradle\u003c/code\u003e script.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003enpm\u003c/strong\u003e uses \u003ca href=\"https://docs.npmjs.com/configuring-npm/package-locks.html\"\u003e\u003ccode\u003epackage-lock.json\u003c/code\u003e\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003ePython has a few tools to solve this problem. Notable is \u003ca href=\"https://github.com/pypa/pipenv\"\u003epipenv\u003c/a\u003e which uses \u003ccode\u003ePipfile.lock\u003c/code\u003e. In a build script, you use the \u003ccode\u003epipenv sync\u003c/code\u003e command which uses the \u003ccode\u003ePipfile.lock\u003c/code\u003e exclusively.\u003c/p\u003e\n\u003ch3 id=\"lock-files-and-pipelines\"\u003eLock files and pipelines\u003c/h3\u003e\n\u003cp\u003eOnce the lock file is generated, commit it to source control. This guarantees that others developers, and build pipelines use the same lock file as you.\u003c/p\u003e\n\u003cp\u003eBe aware that the content of lock files is not written on stone. If you change the main dependency file (\u003ccode\u003e.csproj\u003c/code\u003e, \u003ccode\u003epackages.config\u003c/code\u003e, \u003ccode\u003epackages.json\u003c/code\u003e, etc.), the library package manager updates the lock at the first run, unless you block this behaviour. In a build must \u003cstrong\u003ealways\u003c/strong\u003e force the use of a lock file, that is:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eset MSBuild \u003ccode\u003eRestoreLockedMode\u003c/code\u003e property to \u003ccode\u003etrue\u003c/code\u003e;\u003c/li\u003e\n\u003cli\u003euse \u003ccode\u003edotnet restore\u003c/code\u003e command with the \u003ccode\u003e--locked-mode\u003c/code\u003e option;\u003c/li\u003e\n\u003cli\u003euse \u003ccode\u003enpm ci\u003c/code\u003e \u003cstrong\u003enot\u003c/strong\u003e \u003ccode\u003enpm install\u003c/code\u003e;\u003c/li\u003e\n\u003cli\u003euse \u003ccode\u003epipenv sync\u003c/code\u003e \u003cstrong\u003enot\u003c/strong\u003e \u003ccode\u003epipenv install\u003c/code\u003e;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lost-source\"\u003eLost source\u003c/h3\u003e\n\u003cp\u003eWe still have one scenario depicted in the table: how to cope with library versions that are no more available.\nIf you think that it never happens, please read the \u003ca href=\"https://www.theregister.com/2016/03/23/npm_left_pad_chaos/\"\u003estory of left-pad\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe solution is to add some kind of buffer between your build and the external world, a storage for input artifacts. There quite a number of products, generally labelled as \u003cem\u003eArtifact Store\u003c/em\u003e or  \u003cem\u003eArtifact Manager\u003c/em\u003e: \u003ca href=\"https://jfrog.com/artifactory/\"\u003eArtifactory\u003c/a\u003e, \u003ca href=\"https://www.myget.org/\"\u003eMyGet\u003c/a\u003e, \u003ca href=\"https://www.sonatype.com/product-nexus-repository\"\u003eNexus\u003c/a\u003e, \u003ca href=\"https://inedo.com/proget\"\u003eProGet\u003c/a\u003e, \u003ca href=\"https://docs.microsoft.com/en-us/azure/devops/artifacts\"\u003eAzure Artifacts\u003c/a\u003e and so on.\u003c/p\u003e\n\u003cp\u003eThese products require some tweaks on the build configuration so that the library package manager asks the Artifact Manager before going to the original source. NuGet uses the \u003ca href=\"\"\u003e\u003ccode\u003eNuGet.Config\u003c/code\u003e file\u003c/a\u003e at machine or user level to search for sources; npm leverages the \u003ca href=\"https://docs.npmjs.com/misc/config#registry\"\u003e\u003ccode\u003eregistry\u003c/code\u003e\u003c/a\u003e key in its configuration and so on.\nThe Artifact Manager returns the library package, if available locally, or goes to the original source and cache it locally.\u003c/p\u003e\n\u003cp\u003eArtifact Managers offer support to the most common library package formats (Maven, npm, NuGet, etc.) and a caching mechanism that shields you from a sudden disappearance of a library.\u003c/p\u003e\n\u003ch3 id=\"tool-chain-issues\"\u003eTool chain issues\u003c/h3\u003e\n\u003cp\u003eThe final piece is the library package manager tool itself. Matching algorithms, syntax, all might change on newer version. It is important to have copies of the executable, its configuration.\nThe golden rule is being able to recreate the exact build environment that was used at any point in the past. I discussed the value of Docker in details in \u003ca href=\"http://blog.casavian.eu/2019/08/19/meta-pipelines-introduction/\"\u003ethis article\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"same-tests-different-results\"\u003eSame tests, different results\u003c/h2\u003e\n\u003cp\u003eFlaky tests are the third major cause of uncertainty in builds. Flaky tests randomly pass or fail despite the build being identical.\u003c/p\u003e\n\u003cp\u003eWhat kind of test can be so unpredictable? Tests that depends on external resources. For example, you deploy a web application and run a smoke test that checks if the site is up; if the web application host is slow to start, the remote call may time-out and the test fails. Unit tests, by definition, do not depends on external resources, so your focus should be on integration tests. Design integration tests for predictability; it is better that a whole suite of tests fails. e.g. by checking connectivity at entering the suite, than having a random test of the suite failing. Another scenario might be that tests have an implicit order, and the runner executes them in parallel, thus the random outcome.\nMartin Fowler wrote a beautiful \u003ca href=\"https://martinfowler.com/articles/nonDeterminism.html\"\u003eessay on flaky tests\u003c/a\u003e and I recommend studying it to gain a deep understanding why this happens and some preventions.\u003c/p\u003e\n\u003ch3 id=\"how-to-harness\"\u003eHow to harness\u003c/h3\u003e\n\u003cp\u003ePractitioner have to face the reality of unforeseen problems. Luckily, modern build tools offer some relief.\nYou can automatically re-run failed tests and report which tests pass on the second (or more) attempt.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ein Azure DevOps you turn on this feature at the project level (\u003ca href=\"https://docs.microsoft.com/en-us/azure/devops/pipelines/test/flaky-test-management\"\u003ehttps://docs.microsoft.com/en-us/azure/devops/pipelines/test/flaky-test-management\u003c/a\u003e);\u003c/li\u003e\n\u003cli\u003eJenkins has a plugin named \u003ca href=\"https://plugins.jenkins.io/flaky-test-handler/\"\u003e\u003cem\u003eFlaky Test Handler\u003c/em\u003e\u003c/a\u003e somewhat limited;\u003c/li\u003e\n\u003cli\u003eGitLab suggests a \u003ca href=\"https://about.gitlab.com/handbook/engineering/quality/guidelines/debugging-qa-test-failures/#flaky-test\"\u003esophisticated process\u003c/a\u003e that accounts for a number of failure scenarios, allowing tagging tests so the build pipeline knows about flakiness or other issues.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"in-summary\"\u003eIn summary\u003c/h2\u003e\n\u003cp\u003eWe explored cursory the topic of non-predictable builds. The root of randomness may lie in the compiler, the linker, the library manager, the dependency manager, in the test suites.\nThere are options, tools and techniques that help in minimise or even completely get rid of variation and have fully reproducible builds.\nYou should aim at repeatable, even reproducible builds: they are a defense weapon for the developer in the modern world.\nA final word for the tool-chain. If you need to go back and rebuild years old versions, you must archive the exact set of tools you use for building and keep it safe. A different version for a compiler or a library manager can have a big impact on your ability to reproduce an old version.\u003c/p\u003e\n\u003chr\u003e\n\u003csection class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n\u003cp\u003e\u0026ldquo;Anything that can go wrong will go wrong\u0026rdquo;. \u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n\u003cp\u003eRaymond Chen\u0026rsquo;s post \u003ca href=\"https://devblogs.microsoft.com/oldnewthing/20100318-00/?p=14563\"\u003eWhat is DLL import binding?\u003c/a\u003e and also \u003ca href=\"https://devblogs.microsoft.com/oldnewthing/20180103-00/?p=97705\"\u003eWhy are the module timestamps in Windows 10 so nonsensical?\u003c/a\u003e. \u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n\u003cp\u003eMSBuild documentation \u003ca href=\"https://docs.microsoft.com/en-us/visualstudio/msbuild/customize-your-build\"\u003eCustomize your build\u003c/a\u003e. \u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:4\" role=\"doc-endnote\"\u003e\n\u003cp\u003eProgram database (PDB) is Microsoft\u0026rsquo;s file format for storing debugging information. \u003ca href=\"#fnref:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:5\" role=\"doc-endnote\"\u003e\n\u003cp\u003eSource \u003ca href=\"https://octoverse.github.com/#dependencies-overview\"\u003eGitHub\u003c/a\u003e: \u0026ldquo;\u003cem\u003e203 package dependencies, on average, support every public and private repository with an enabled dependency graph\u003c/em\u003e\u0026rdquo; \u003ca href=\"#fnref:5\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e\n"},{"title":"Top 10 Pipeline mistakes","date_published":"2020-05-23T14:00:00+01:00","date_modified":"2020-05-23T14:00:00+01:00","id":"http://www.getlatestversion.eu/2020/05/top-10-pipeline-mistakes/","url":"http://www.getlatestversion.eu/2020/05/top-10-pipeline-mistakes/","author":{"name":"Giulio Vian"},"content_html":"\u003cp\u003eToday I am going to start a series of posts detailing common issues or mistakes in a DevOps context.\nI will try to refer to my experience and add some practical suggestion to identify and solve these issues.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s start with my list of top 10 CI/CD pipeline issues.\u003c/p\u003e\n\u003ch2 id=\"the-list\"\u003eThe list\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE\u003c/strong\u003e:\u003cbr\u003e\nPublished posts are in \u003cstrong\u003ebold\u003c/strong\u003e, the link for items in \u003cem\u003eitalic\u003c/em\u003e  does not work.\u003cbr\u003e\nLast update: 10 June 2020\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"../sloppy-secrets-handling\"\u003e\u003cem\u003eSloppy handling of Secrets\u003c/em\u003e\u003c/a\u003e \u0026ndash; leaking or hard-coding passwords, tokens or similar sensitive data;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../untraceable-artifacts\"\u003e\u003cem\u003eUntraceable artifacts\u003c/em\u003e\u003c/a\u003e \u0026ndash; when builds produce (or worse: deploy!) binaries of unknown source and version; this is a major red flag because it is cheap and easy to fix, but it is usually overlooked causing a major technical debt pile-up;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../too-specific\"\u003e\u003cem\u003eToo specific\u003c/em\u003e\u003c/a\u003e \u0026ndash; if your artifacts are not scrubbed from environment-specific dependencies, so they cannot be deployed to all environments;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../what-quality\"\u003e\u003cem\u003eWhat, quality?\u003c/em\u003e\u003c/a\u003e \u0026ndash; when your pipeline does not contain any check on quality, what do you expect as a result?;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../bleeding-edge\"\u003e\u003cem\u003eBleeding edge\u003c/em\u003e\u003c/a\u003e \u0026ndash; using the latest and greatest technology is not always a wise choice;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../galactic-builds\"\u003e\u003cem\u003eGalactic Builds\u003c/em\u003e\u003c/a\u003e \u0026ndash; far-reaching builds that slow teams down instead of helping them;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../flaky-builds\"\u003e\u003cstrong\u003eFlaky builds\u003c/strong\u003e\u003c/a\u003e \u0026ndash; builds generating unreproducible behaviours or random artefacts;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../../06/flaky-builds\"\u003e\u003cstrong\u003eFlaky builds\u003c/strong\u003e\u003c/a\u003e \u0026ndash; builds generating unreproducible behaviours or random artefacts;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../too-much-of-a-good-thing\"\u003e\u003cem\u003eToo much of a good thing\u003c/em\u003e\u003c/a\u003e \u0026ndash; when you go too far to avoid the above mistakes, causing the fix to backfire;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../implicit-assumption\"\u003e\u003cem\u003eImplicit assumption\u003c/em\u003e\u003c/a\u003e \u0026ndash; any build that breaks when some undocumented environmental condition change;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"../untamed-plugins\"\u003e\u003cem\u003eUntamed plugins\u003c/em\u003e\u003c/a\u003e \u0026ndash; similar to the previous one, it is the nightmare of people that manage your build environments, when the build software uses too many, or even conflicting plugins.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe list is not really complete: there is one more to add.\u003c/p\u003e\n\u003ch2 id=\"the-unforgivable-sin-having-no-pipeline\"\u003eThe unforgivable sin: having no pipeline\u003c/h2\u003e\n\u003cp\u003eThis is the ultimate sin of any developer: having no automated process of any kind.\u003cbr\u003e\nAt a minimum you can have a simple bash or PowerShell script to compile and publish your project.\nWith that it is going to be easy to integrate it in any of the most popular Continuous Integration tools: Jenkins, Azure DevOps, GitHub Actions, GitLab, TeamCity, etc.\u003cbr\u003e\nThat script should check for dependencies and label the produced artifacts with a version number. This will be discussed in detail in future posts.\u003cbr\u003e\nIf you do not need to automate the process for other people, at least, automate it for your future self!\u003c/p\u003e\n\u003cp\u003eSee you soon with the next episode.\u003c/p\u003e\n"},{"title":"Code dependencies: Binary Composition is not only a mathematics calculation","date_published":"2020-05-17T16:00:00+02:00","date_modified":"2020-05-17T16:00:00+02:00","id":"http://www.getlatestversion.eu/2020/05/code-dependencies-binary-composition-is-not-only-a-mathematics-calculation/","url":"http://www.getlatestversion.eu/2020/05/code-dependencies-binary-composition-is-not-only-a-mathematics-calculation/","author":{"name":"Bartolomeo Lombardi"},"content_html":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eOver the years, the growing code base of application software with multiple teams working on the same product, has lead to break up the solution into multiple solutions. This has been done trying to reduce the time required for the build and for their integration, to ease Integrated Development Environment in opening hundreds of projects, and other.\nThe main consequence of having multiple solutions is binary composition.\u003c/p\u003e\n\u003ch1 id=\"what-is-binary-composition\"\u003eWhat is binary composition?\u003c/h1\u003e\n\u003cp\u003eBinary composition occurs when one or more solutions reference the compiled binaries of another solution. Let suppose it is needed to make the binaries of Solution B available to Solution A before Solution A can build successfully.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"visual-studio-references.jpg\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eIf you are forced to commit the code together with the binaries produced by build in the repository\u0026hellip;Keep on reading :)\u003c/p\u003e\n\u003ch1 id=\"how-can-we-distribute-binaries\"\u003eHow can we distribute binaries?\u003c/h1\u003e\n\u003cp\u003eWe can make those binaries available in several ways.\u003c/p\u003e\n\u003ch2 id=\"git-repository\"\u003eGit repository\u003c/h2\u003e\n\u003cp\u003eA first possibility consists in committing them into a repository anytime a merge into the development/master branch by means of the Continuous Integration build pipeline is requested by a Pull Request. Of course, this increases the size of the repository introducing significant slowdown checkout times and performances. Imagine what could happen if teams work on different branches ending up using different versions of the same binaries creating merge conflicts.\u003c/p\u003e\n\u003ch2 id=\"file-share\"\u003eFile share\u003c/h2\u003e\n\u003cp\u003eAnother option consists in putting the binaries onto a file share. In this case, however, there is no index to find binaries quickly and there is no protection against overriding a version.\u003c/p\u003e\n\u003ch2 id=\"package-management-with-azure-artifacts\"\u003ePackage Management with Azure Artifacts\u003c/h2\u003e\n\u003cp\u003eThis should definitely be the most suitable solution because it allows putting binaries into NuGet (and other as npm, Maven, Python, and universal) packages making it possible for Solution A to reference these packages. Among the several advantages introduced by this methodology, in Continuous Integration Azure pipeline a NuGet published task can be added in order to make the update versioning procedure automatic and distributing it in a reliable way also.\u003c/p\u003e\n"},{"title":"Reducing the gap between operations and development using Azure DevOps","date_published":"2020-05-15T11:30:00+02:00","date_modified":"2020-05-15T11:30:00+02:00","id":"http://www.getlatestversion.eu/2020/05/reducing-the-gap-between-operations-and-development-using-azure-devops/","url":"http://www.getlatestversion.eu/2020/05/reducing-the-gap-between-operations-and-development-using-azure-devops/","author":{"name":"Alessandro Alpi"},"content_html":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cp\u003eAs we all know, DevOps is culture. In a company that is going to adopt its practices and principles, everyone should be \u0026ldquo;on the same side\u0026rdquo;. Continuous improvement cannot be part of our work in IT if we wouldn\u0026rsquo;t reduce the gap between development and operations. People like me, that worked in the 90s, know that dev and ops were always isolated in silos and this was \u0026ldquo;the only\u0026rdquo; way that everyone followed as a suggestion taken from the market leaders. Ticketing systems and extreme bureaucracy acted as a man-in-the-middle between those silos, transforming each organization in two people-unaware endpoints.\u003c/p\u003e\n\u003cp\u003eSpeaking from a DevOps perspective, in such circumstances, a developer couldn\u0026rsquo;t know anything about how to deploy, where and how is an environment configured. On the other hand, an operation guy couldn\u0026rsquo;t get anything from a package in terms of what the application has been made for. Due to this gap we often see performance issues, underestimated hardware stuff and delayed releases. Last but not least, what about the lack of commitment and accountability of the employees working on the solution? In short, reducing such a gap is possible using a combination of DevOps culture and the right tools. We will see hereafter how my organization tries to do so using Azure DevOps.\u003c/p\u003e\n\u003ch2 id=\"scenario\"\u003eScenario\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s get started with our team (DevTeam hereafter), which is working with agile methodologies, composed of ten developers and a PO. A quick note, we are using a process decision framework called \u003ca href=\"https://www.disciplinedagileconsortium.org\"\u003eDisciplined Agile\u003c/a\u003e. Then, we have three operation professionals (OpsTeam from now on). Build and deploy pipelines already exist. Builds are hosted by \u003ca href=\"https://azure.microsoft.com/it-it/services/devops/\"\u003eAzure DevOps (cloud)\u003c/a\u003e and deploys are managed by \u003ca href=\"https://octopus.com/\"\u003eOctopus Deploy\u003c/a\u003e. Getting this, has been a difficult mission.\u003c/p\u003e\n\u003cp\u003eEverything is related to infrastructure in terms of servers, operative systems, virtual hosts, DNS, firewalls, security and so on, is the responsibility of our OpsTeam. As a result, they do many tasks for managing the environments. Here comes the problem. DevTeams used to create tasks in a dedicated backlog, but OpsTeam didn\u0026rsquo;t. It\u0026rsquo;s not just a matter of end-of-pipeline tasks, but also tasks for their daily basis work.\u003c/p\u003e\n\u003ch2 id=\"our-solution\"\u003eOur solution\u003c/h2\u003e\n\u003cp\u003eModify the tool, adapting its shape in order to fit in with that real scenario. A piece of cake, when you\u0026rsquo;re DevOps \u0026ldquo;inside\u0026rdquo;. How did we change Azure DevOps? Let\u0026rsquo;s describe what we did in three parts:\u003c/p\u003e\n\u003ch3 id=\"teams-in-azure-devops\"\u003eTeams in Azure DevOps\u003c/h3\u003e\n\u003cp\u003eTo create a team in Azure DevOps is really a piece of cake (according to the latest releases). Just navigate to the options and select \u003cem\u003eTeams\u003c/em\u003e:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-01-team-on-azuredevops.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWe can add many teams clicking on \u003cem\u003eNew team\u003c/em\u003e:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-02-new-team.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWe can set the team\u0026rsquo;s administrators, the permission set and an area under which every work item will be created. This area will be one of our best friends, especially when we will make our queries for gathering and analyzing the team\u0026rsquo;s related data. Additionally, also the other teams\u0026rsquo; members could create items with this area in order to make the OpsTeam aware of them.\u003c/p\u003e\n\u003cp\u003eTeam\u0026rsquo;s backlog\nNow let\u0026rsquo;s navigate to Backlogs:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-03-backlogs.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eGood! The new backlog has been created. Going on it, we will see the team\u0026rsquo;s drop-down as well as the one for iterations. Great feature!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-04-sprints.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eOnce created, we will see the teams\u0026rsquo; drop-down:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-05-team-switch.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"work-items\"\u003eWork items\u003c/h3\u003e\n\u003cp\u003eNow, let\u0026rsquo;s create a new work item type. We call it Ops item. Navigate to Process customization page:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-06-process.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eBefore adding the new work item, we must ensure that the process is already a custom process, otherwise, all the edits will be blocked as shown in the following picture:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-07-process-custom.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWe\u0026rsquo;ve already created a SimplifiedScrum process. let\u0026rsquo;s add our item now:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-07-workitemtype.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eNow we are going to modify the fields of the new type. Each team should be able to understand all the item\u0026rsquo;s properties. We will leave the item as is in this example. Then, we have to map the type to the backlog item list, since only the default work item types are shown initially. To do this, navigate to the Process customization page, Backlog Levels tab:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-08-process-add-workitemtype-1.png\" alt=\"image.png\"\u003e\n\u003cimg src=\"post01-09-process-add-workitemtype-2.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs we can see, we can also set the default item for our requirements backlog. Moreover, every Sprint backlog, based on iterations, will enable us to add the new Ops item:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-10-new-workitem.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"wrapping-up\"\u003eWrapping up\u003c/h3\u003e\n\u003cp\u003eSo, we\u0026rsquo;ve got a backlog for the IT Operations team\u0026rsquo;s members. Then, we\u0026rsquo;ve related it to their Azure DevOps team. Additionally, we\u0026rsquo;ve got a particular work item type (not mandatory, but really useful for querying it or adding it into dashboards) target of IT Operations\u0026rsquo; job and a dedicated Area Path. We can make many relationships between items of both our backlogs. Here is an example of how an activity can be managed and organized (extension: \u003ca href=\"https://marketplace.visualstudio.com/items?itemName=ms-devlabs.WorkItemVisualization\"\u003eWork Item Visualize\u003c/a\u003e):\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"post01-11-workitem-visualize.png\" alt=\"image.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, the Ops items are \u003cem\u003eSuccessor\u003c/em\u003e of the \u0026ldquo;development\u0026rdquo; Product backlog items. Indeed, the Ops Items will be finished after the PBI, typically. Think about creating s DNS or a network path to let the production app work in production.\u003c/p\u003e\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003c/h2\u003e\n\u003cp\u003eWith this solution, we\u0026rsquo;re decoupling backlogs. Moreover, we\u0026rsquo;re isolating the management maintaining the relationships between work items that reside on different boards. At the same time, we\u0026rsquo;re making a strong synergy between Development and Operations.\nThen, in a couple of clicks, we can switch teams and backlogs, using Azure DevOps Boards. We can track changes in both the departments, also for audit requirements. In my opinion, this helps the enterprise awareness and facilitates the continuous improvement of all the teams and any member\u0026rsquo;s skill.\u003c/p\u003e\n"},{"title":"About","date_published":"0001-01-01T00:00:00Z","date_modified":"0001-01-01T00:00:00Z","id":"http://www.getlatestversion.eu/about/","url":"http://www.getlatestversion.eu/about/","content_html":"\u003cp\u003e\u003cimg src=\"/images/320px-Flag_of_Europe.svg.png\" alt=\"Europe flag\"\u003e\u003c/p\u003e\n\u003ch2 id=\"about-us\"\u003eAbout Us\u003c/h2\u003e\n\u003cp\u003eGetLatestVersion.eu stems from GetLatestVersion.it, the successful Italian community specialised on DevOps, Application Lifecycle Management (ALM) and Software Development Life-Cycle (SDLC).\u003c/p\u003e\n\u003ch2 id=\"what-we-do\"\u003eWhat we do\u003c/h2\u003e\n\u003cp\u003eWe publish posts and articles on DevOps, Agile, tools, design, implementation techniques.\nOur \u003ca href=\"https://www.youtube.com/GetLatestVersion\"\u003eYouTube channel\u003c/a\u003e hosts useful video of different kind: short introductions to a topic or tool, longer presentation on experiences and conference sessions.\nIn addition, we organise events in person and online on DevOps, Agile, ALM and SDLC topics.\u003c/p\u003e\n"},{"title":"Privacy","date_published":"0001-01-01T00:00:00Z","date_modified":"0001-01-01T00:00:00Z","id":"http://www.getlatestversion.eu/page/privacy/","url":"http://www.getlatestversion.eu/page/privacy/","content_html":"\u003ch2 id=\"list-of-cookies-used-in-this-site\"\u003eList of Cookies used in this site\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGoogle Analytics cookies\u003c/strong\u003e: __utma, __utmb, __utmc, __utmv, __utmz, used to gather site statistic usage. You can read more info on Google Policies on: How Google uses data when you use our partners’ sites or apps and Safeguarding your Data.\u003c/p\u003e\n"},{"title":"Search","date_published":"0001-01-01T00:00:00Z","date_modified":"0001-01-01T00:00:00Z","id":"http://www.getlatestversion.eu/search/","url":"http://www.getlatestversion.eu/search/","content_html":"\u003cp class=\"error message js-hidden\"\u003eYou must have Javascript enabled to use this function.\u003c/p\u003e\n\u003cp class=\"search-loading status message hidden\"\u003eLoading search index…\u003c/p\u003e\n\n\u003cdiv class=\"search-input hidden\"\u003e\n  \u003cform id=\"search-form\" class=\"search-form\" action=\"#\" method=\"post\" accept-charset=\"UTF-8\" role=\"search\"\u003e\n    \u003clabel for=\"query\" class=\"visually-hidden\"\u003eSearch\u003c/label\u003e\n    \u003cinput type=\"search\" id=\"query\" name=\"query\" class=\"search-text\" placeholder=\"Enter the terms you wish to search for.\" maxlength=\"128\"\u003e\n    \u003cbutton type=\"submit\" name=\"submit\" class=\"form-submit\" \u003eSearch\u003c/button\u003e\n  \u003c/form\u003e\n\u003c/div\u003e\n\n\u003cdiv class=\"search-results\"\u003e\u003c/div\u003e\n\n\u003ctemplate\u003e\n  \u003carticle class=\"search-result list-view\"\u003e\n    \u003cheader\u003e\n      \u003ch2 class=\"title title-submitted\"\u003e\u003ca href=\"#\"\u003eTitle here\u003c/a\u003e\u003c/h2\u003e\n      \u003cdiv class=\"submitted\"\u003e\u003ctime class=\"created-date\"\u003eDate here\u003c/time\u003e\u003c/div\u003e\n    \u003c/header\u003e\n    \u003cdiv class=\"content\"\u003eSummary here\u003c/div\u003e\n  \u003c/article\u003e\n\u003c/template\u003e\n\n"}]}